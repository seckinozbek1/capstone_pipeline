{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea5aaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\secki\\AppData\\Local\\Temp\\ipykernel_36848\\2972118543.py:87: DtypeWarning: Columns (346,348,350,580,581,582,583) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wvs_full = pd.read_csv(wvs_full_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_COUNTRY_ALPHA</th>\n",
       "      <th>A_YEAR</th>\n",
       "      <th>VOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.634460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.621891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LBY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.613155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEN</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LBN</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.502941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MMR</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.500617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AND</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.473307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JPN</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.448386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IRN</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.431660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>URY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.416842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.376068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CZE</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.358696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KOR</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.353414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ECU</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MAR</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COL</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.337719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VNM</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.329487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.309029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KEN</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.308935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PER</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.305042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TUN</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.291391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IRQ</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.249716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CHL</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MEX</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.231668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GTM</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.191794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RUS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.190247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UKR</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.188641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KAZ</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.175355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>JOR</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.172716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UZB</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GRC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GBR</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.166238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NIC</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>USA</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.163096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NGA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.160065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EGY</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TUR</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.156167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ROU</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.154429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KGZ</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.151250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MYS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.148938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.139979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NZL</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.133802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DEU</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.127040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NLD</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.116711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BOL</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.111062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AUS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.104011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PAK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.102568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>THA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.094286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>IDN</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.064931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.041065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CYP</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BGD</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CHN</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PHL</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TJK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SGP</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SVK</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B_COUNTRY_ALPHA  A_YEAR     VOICE\n",
       "0              ARG    2017  0.634460\n",
       "1              SRB    2017  0.621891\n",
       "2              LBY    2022  0.613155\n",
       "3              VEN    2021  0.588235\n",
       "4              LBN    2018  0.502941\n",
       "5              MMR    2020  0.500617\n",
       "6              AND    2018  0.473307\n",
       "7              JPN    2019  0.448386\n",
       "8              IRN    2020  0.431660\n",
       "9              URY    2022  0.416842\n",
       "10             ZWE    2020  0.376068\n",
       "11             CZE    2022  0.358696\n",
       "12             KOR    2018  0.353414\n",
       "13             ECU    2018  0.350000\n",
       "14             MAR    2021  0.350000\n",
       "15             COL    2018  0.337719\n",
       "16             VNM    2020  0.329487\n",
       "17             MDV    2021  0.309029\n",
       "18             KEN    2021  0.308935\n",
       "19             PER    2018  0.305042\n",
       "20             TUN    2019  0.291391\n",
       "21             IRQ    2018  0.288462\n",
       "22             BRA    2018  0.249716\n",
       "23             CHL    2018  0.237600\n",
       "24             MEX    2018  0.231668\n",
       "25             GTM    2020  0.191794\n",
       "26             RUS    2017  0.190247\n",
       "27             UKR    2020  0.188641\n",
       "28             KAZ    2018  0.175355\n",
       "29             JOR    2018  0.172716\n",
       "30             UZB    2022  0.171429\n",
       "31             GRC    2017  0.169231\n",
       "32             GBR    2022  0.166238\n",
       "33             NIC    2020  0.165000\n",
       "34             USA    2017  0.163096\n",
       "35             NGA    2018  0.160065\n",
       "36             EGY    2018  0.157143\n",
       "37             TUR    2018  0.156167\n",
       "38             ROU    2018  0.154429\n",
       "39             KGZ    2020  0.151250\n",
       "40             MYS    2018  0.148938\n",
       "41             ETH    2020  0.139979\n",
       "42             NZL    2020  0.133802\n",
       "43             DEU    2018  0.127040\n",
       "44             NLD    2022  0.116711\n",
       "45             BOL    2017  0.111062\n",
       "46             AUS    2018  0.104011\n",
       "47             PAK    2018  0.102568\n",
       "48             THA    2018  0.094286\n",
       "49             IDN    2018  0.064931\n",
       "50             CAN    2020  0.041065\n",
       "51             CYP    2019  0.000000\n",
       "52             BGD    2018  0.000000\n",
       "53             CHN    2018  0.000000\n",
       "54             PHL    2019  0.000000\n",
       "55             TJK    2020  0.000000\n",
       "56             SGP    2020  0.000000\n",
       "57             SVK    2022  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Load datasets\n",
    "q152 = pd.read_csv(\"q152_country_year_top2_labels.csv\")\n",
    "q154 = pd.read_csv(\"q154_country_year_top2_labels.csv\")\n",
    "\n",
    "# Merge on country and year, keep only rows where has_second_label==True in both\n",
    "merged = pd.merge(\n",
    "    q152[q152['has_second_label'] == True],\n",
    "    q154[q154['has_second_label'] == True],\n",
    "    on=['B_COUNTRY_ALPHA', 'A_YEAR'],\n",
    "    suffixes=('_152', '_154')\n",
    ")\n",
    "\n",
    "# Function to extract question and likert scale from label string (e.g. 'Q152_2')\n",
    "def extract_q_likert(label):\n",
    "    if pd.isna(label):\n",
    "        return (None, np.nan)\n",
    "    parts = label.split('_')\n",
    "    if len(parts) != 2:\n",
    "        return (None, np.nan)\n",
    "    return parts[0], int(parts[1])\n",
    "\n",
    "# Extract qid and likert scale for all relevant columns\n",
    "for col in ['most_frequent_label_152', 'second_most_frequent_label_152',\n",
    "            'most_frequent_label_154', 'second_most_frequent_label_154']:\n",
    "    merged[[f'{col}_qid', f'{col}_likert']] = merged[col].apply(lambda x: pd.Series(extract_q_likert(x)))\n",
    "\n",
    "# Map likert scales for each question\n",
    "merged['Q152_likert'] = merged['most_frequent_label_152_likert']\n",
    "merged['Q153_likert'] = merged['second_most_frequent_label_152_likert']\n",
    "merged['Q154_likert'] = merged['most_frequent_label_154_likert']\n",
    "merged['Q155_likert'] = merged['second_most_frequent_label_154_likert']\n",
    "\n",
    "# Voice component functions without coefficients\n",
    "def compute_I_VOICE1(q154, q155):\n",
    "    if pd.isna(q154) or pd.isna(q155):\n",
    "        return np.nan\n",
    "    if (q154 == 2 and q155 == 4) or (q154 == 4 and q155 == 2):\n",
    "        return 1\n",
    "    if (q154 == 2 and q155 != 4) or (q154 == 4 and q155 != 2):\n",
    "        return 0.66\n",
    "    if (q154 != 2 and q155 == 4) or (q154 != 4 and q155 == 2):\n",
    "        return 0.33\n",
    "    if q154 > -1 and q155 > -1:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "def compute_I_VOICE2(q152, q153):\n",
    "    if pd.isna(q152) or pd.isna(q153):\n",
    "        return np.nan\n",
    "    if q152 == 3:\n",
    "        return 1\n",
    "    if q153 == 3:\n",
    "        return 0.5\n",
    "    if q152 > -1 and q153 > -1:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "# Calculate raw VOICE components, skipping metrics if NA\n",
    "merged['I_VOICE1'] = merged.apply(lambda r: compute_I_VOICE1(r['Q154_likert'], r['Q155_likert']), axis=1)\n",
    "merged['I_VOICE2'] = merged.apply(lambda r: compute_I_VOICE2(r['Q152_likert'], r['Q153_likert']), axis=1)\n",
    "\n",
    "# Multiply by corresponding counts (weights)\n",
    "merged['weighted_I_VOICE1'] = merged['I_VOICE1'] * (\n",
    "    merged['most_frequent_count_154'].fillna(0) + merged['second_most_frequent_count_154'].fillna(0)\n",
    ")\n",
    "merged['weighted_I_VOICE2'] = merged['I_VOICE2'] * (\n",
    "    merged['most_frequent_count_152'].fillna(0) + merged['second_most_frequent_count_152'].fillna(0)\n",
    ")\n",
    "\n",
    "# Sum counts for normalization, skipping counts where voice component is nan\n",
    "merged['total_counts'] = (\n",
    "    (merged['most_frequent_count_152'].fillna(0) + merged['second_most_frequent_count_152'].fillna(0)) * (~merged['I_VOICE2'].isna()).astype(int) +\n",
    "    (merged['most_frequent_count_154'].fillna(0) + merged['second_most_frequent_count_154'].fillna(0)) * (~merged['I_VOICE1'].isna()).astype(int)\n",
    ")\n",
    "\n",
    "# Compute weighted average VOICE score\n",
    "merged['VOICE_weighted'] = (\n",
    "    (merged['weighted_I_VOICE1'].fillna(0) + merged['weighted_I_VOICE2'].fillna(0)) / merged['total_counts'].replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# Load full WVS dataset with survey weights\n",
    "wvs_full_path = r\"C:\\Users\\secki\\OneDrive\\Desktop\\MY498 Capstone Under Supervision\\WVS Wave 7 Full Package for EFA\\F00010736-WVS_Cross-National_Wave_7_rdata_v6_0\\wvs7_full_data.csv\"\n",
    "wvs_full = pd.read_csv(wvs_full_path)\n",
    "\n",
    "# Select only needed columns and drop duplicates\n",
    "wvs_weights = wvs_full[['B_COUNTRY_ALPHA', 'A_YEAR', 'S018']].drop_duplicates()\n",
    "\n",
    "# Merge survey weights into merged dataframe\n",
    "merged = pd.merge(\n",
    "    merged,\n",
    "    wvs_weights,\n",
    "    on=['B_COUNTRY_ALPHA', 'A_YEAR'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate VOICE weighted by survey weights (handle missing survey weights by skipping multiplication)\n",
    "merged['VOICE_weighted_survey'] = merged.apply(\n",
    "    lambda r: r['VOICE_weighted'] * r['S018'] if not pd.isna(r['VOICE_weighted']) and not pd.isna(r['S018']) else r['VOICE_weighted'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Prepare final output dataframe and sort descending\n",
    "voice_df_weighted = merged[['B_COUNTRY_ALPHA', 'A_YEAR', 'VOICE_weighted_survey']].copy()\n",
    "voice_df_weighted = voice_df_weighted.rename(columns={'VOICE_weighted_survey': 'VOICE'})\n",
    "voice_df_weighted = voice_df_weighted.sort_values(by='VOICE', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display final results\n",
    "display(voice_df_weighted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4afdf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['S025', 'B_COUNTRY', 'B_COUNTRY_ALPHA', 'A_YEAR', 'SCEPTICISM',\n",
      "       'RELATIVISM', 'DISBELIEF', 'DEFIANCE', 'SACSECVAL', 'AUTONOMY',\n",
      "       'EQUALITY', 'CHOICE', 'VOICE', 'RESEMAVAL'],\n",
      "      dtype='object')\n",
      "Merged dataset size: 58\n",
      "Pearson correlation between calculated VOICE and WVS VOICE: -0.0746 (p-value = 0.5776)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load your sparse voice_df from previous steps (make sure voice_df is available)\n",
    "# voice_df = ...  # Already available from previous processing\n",
    "\n",
    "# Load full WVS country-year voice dataset\n",
    "wvs_full_path = r\"C:\\Users\\secki\\OneDrive\\Desktop\\MY498 Capstone Under Supervision\\WVS Wave 7 Full Package for EFA\\F00010736-WVS_Cross-National_Wave_7_rdata_v6_0\\wvs_countryyear_full_components.csv\"\n",
    "wvs_df = pd.read_csv(wvs_full_path)\n",
    "\n",
    "# Inspect column names in wvs_df to find the VOICE variable and country/year column names\n",
    "print(wvs_df.columns)\n",
    "\n",
    "# Suppose country and year columns are 'country' and 'year' and voice column is 'VOICE' (adjust if different)\n",
    "# Rename columns in wvs_df to match voice_df if needed\n",
    "wvs_df.rename(columns={'country': 'B_COUNTRY_ALPHA', 'year': 'A_YEAR'}, inplace=True)\n",
    "\n",
    "# Merge the two datasets on country and year, inner join to keep only common observations\n",
    "merged_df = pd.merge(\n",
    "    voice_df_weighted,\n",
    "    wvs_df[['B_COUNTRY_ALPHA', 'A_YEAR', 'VOICE']],\n",
    "    on=['B_COUNTRY_ALPHA', 'A_YEAR'],\n",
    "    how='inner',\n",
    "    suffixes=('_calc', '_wvs')\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset size: {len(merged_df)}\")\n",
    "\n",
    "# Calculate Pearson correlation between the two VOICE measures\n",
    "corr, p_value = pearsonr(merged_df['VOICE_calc'], merged_df['VOICE_wvs'])\n",
    "\n",
    "print(f\"Pearson correlation between calculated VOICE and WVS VOICE: {corr:.4f} (p-value = {p_value:.4g})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
